model_name: "mistralai/Mistral-7B-v0.1"
dataset_path: "src/mtl4ad/resources/train/dataset"
per_device_train_batch_size: 8
per_device_eval_batch_size: 8
gradient_checkpointing: true
gradient_accumulation_steps: 2
model_max_length: 8192
experiment_name: mistral_train_1
checkpoint_dir: "models"
deepspeed: "configs/deepspeed_config.json"
dataset_percentage: 10
dataset_seed: 42
shuffle: true
enable_peft: true
eval_steps: 1000
logging_steps: 1000
save_total_limit: 10
save_steps: 1000
eval_strategy: "steps"
num_train_epochs: 1
report_to: "mlflow"