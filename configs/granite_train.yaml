model_name: "ibm-granite/granite-7b-base"
dataset_path: "src/mtl4ad/resources/train/dataset"
per_device_train_batch_size: 8
per_device_eval_batch_size: 8
gradient_checkpointing: true
gradient_accumulation_steps: 4
experiment_name: full_train_no_deepspeed
checkpoint_dir: "models"
# deepspeed: "configs/deepspeed_config.json" #"configs/deepspeed_config.json"
dataset_percentage: 100
dataset_seed: 42
shuffle: true
enable_peft: true
eval_steps: 5000
logging_steps: 100
save_total_limit: 10
save_steps: 50
eval_strategy: "steps"
num_train_epochs: 1
# max_steps: 100
report_to: "none"
max_seq_length: 4096
ddp_backend: "nccl"
process_group_timeout_in_minutes: 50
# resume_from_checkpoint: "/home/ynanateukam/mtl4ad/models/test_no_deepspeed/checkpoint-50"
# optim: "adamw_bnb_8bit"